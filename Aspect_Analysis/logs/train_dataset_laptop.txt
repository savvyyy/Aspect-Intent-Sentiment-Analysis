(base) itadmin@Aditya:~/Desktop/machine learning tutorials/Aspect Analysis$ python script/train_dataset.py --domain 'laptop'
Using TensorFlow backend.
2020-04-24 09:50:43.049462: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-24 09:50:43.049594: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-04-24 09:50:43.049621: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Run: 0
script/train_dataset.py:103: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  score=torch.nn.functional.nll_loss(torch.nn.functional.log_softmax(x_logit.data), y.data)
script/train_dataset.py:130: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(parameters, 1.)
Epoch: 0, Loss: 0.267440
Epoch: 1, Loss: 0.235496
Epoch: 2, Loss: 0.213879
Epoch: 3, Loss: 0.194935
Epoch: 4, Loss: 0.186147
Epoch: 5, Loss: 0.176970
Epoch: 6, Loss: 0.161970
Epoch: 7, Loss: 0.155178
Epoch: 8, Loss: 0.142474
Epoch: 9, Loss: 0.144337
Epoch: 10, Loss: 0.133710
Epoch: 11, Loss: 0.132952
Epoch: 12, Loss: 0.131761
Epoch: 13, Loss: 0.131183
Epoch: 14, Loss: 0.120278
Epoch: 15, Loss: 0.125526
Epoch: 16, Loss: 0.129420
Epoch: 17, Loss: 0.118307
Epoch: 18, Loss: 0.115612
Epoch: 19, Loss: 0.121026
Epoch: 20, Loss: 0.116911
Epoch: 21, Loss: 0.109735
Epoch: 22, Loss: 0.110294
Epoch: 23, Loss: 0.109535
Epoch: 24, Loss: 0.105475
Epoch: 25, Loss: 0.115025
Epoch: 26, Loss: 0.096622
Epoch: 27, Loss: 0.110602
Epoch: 28, Loss: 0.105502
Epoch: 29, Loss: 0.096742
Epoch: 30, Loss: 0.101872
Epoch: 31, Loss: 0.095195
Epoch: 32, Loss: 0.097357
Epoch: 33, Loss: 0.103554
Epoch: 34, Loss: 0.093754
Epoch: 35, Loss: 0.099875
Epoch: 36, Loss: 0.101564
Epoch: 37, Loss: 0.098203
Epoch: 38, Loss: 0.096793
Epoch: 39, Loss: 0.094785
Epoch: 40, Loss: 0.095304
Epoch: 41, Loss: 0.096911
Epoch: 42, Loss: 0.085865
Epoch: 43, Loss: 0.093980
Epoch: 44, Loss: 0.098577
Epoch: 45, Loss: 0.090075
Epoch: 46, Loss: 0.090343
Epoch: 47, Loss: 0.084780
Epoch: 48, Loss: 0.085982
Epoch: 49, Loss: 0.093023
Epoch: 50, Loss: 0.085548
Epoch: 51, Loss: 0.084396
Epoch: 52, Loss: 0.090000
Epoch: 53, Loss: 0.081175
Epoch: 54, Loss: 0.081048
Epoch: 55, Loss: 0.091041
Epoch: 56, Loss: 0.084265
Epoch: 57, Loss: 0.083737
Epoch: 58, Loss: 0.078557
Epoch: 59, Loss: 0.082414
Epoch: 60, Loss: 0.080557
Epoch: 61, Loss: 0.080647
Epoch: 62, Loss: 0.086369
Epoch: 63, Loss: 0.076114
Epoch: 64, Loss: 0.086839
Epoch: 65, Loss: 0.084270
Epoch: 66, Loss: 0.079570
Epoch: 67, Loss: 0.074231
Epoch: 68, Loss: 0.077610
Epoch: 69, Loss: 0.079155
Epoch: 70, Loss: 0.075642
Epoch: 71, Loss: 0.080812
Epoch: 72, Loss: 0.080637
Epoch: 73, Loss: 0.077552
Epoch: 74, Loss: 0.081720
Epoch: 75, Loss: 0.076506
Epoch: 76, Loss: 0.078090
Epoch: 77, Loss: 0.077660
Epoch: 78, Loss: 0.078805
Epoch: 79, Loss: 0.075176
Epoch: 80, Loss: 0.080678
Epoch: 81, Loss: 0.076912
Epoch: 82, Loss: 0.079956
Epoch: 83, Loss: 0.079306
Epoch: 84, Loss: 0.069684
Epoch: 85, Loss: 0.080565
Epoch: 86, Loss: 0.073592
Epoch: 87, Loss: 0.073834
Epoch: 88, Loss: 0.076885
Epoch: 89, Loss: 0.071153
Epoch: 90, Loss: 0.067941
Epoch: 91, Loss: 0.076492
Epoch: 92, Loss: 0.068427
Epoch: 93, Loss: 0.076321
Epoch: 94, Loss: 0.071754
Epoch: 95, Loss: 0.076057
Epoch: 96, Loss: 0.077719
Epoch: 97, Loss: 0.069915
Epoch: 98, Loss: 0.073058
Epoch: 99, Loss: 0.072805
Epoch: 100, Loss: 0.067979
Epoch: 101, Loss: 0.071711
Epoch: 102, Loss: 0.069450
Epoch: 103, Loss: 0.070206
Epoch: 104, Loss: 0.073081
Epoch: 105, Loss: 0.072389
Epoch: 106, Loss: 0.068437
Epoch: 107, Loss: 0.074764
Epoch: 108, Loss: 0.066619
Epoch: 109, Loss: 0.067524
Epoch: 110, Loss: 0.074195
Epoch: 111, Loss: 0.073004
Epoch: 112, Loss: 0.070512
Epoch: 113, Loss: 0.075681
Epoch: 114, Loss: 0.071188
Epoch: 115, Loss: 0.067113
Epoch: 116, Loss: 0.073986
Epoch: 117, Loss: 0.067997
Epoch: 118, Loss: 0.068097
Epoch: 119, Loss: 0.071350
Epoch: 120, Loss: 0.065649
Epoch: 121, Loss: 0.073132
Epoch: 122, Loss: 0.071653
Epoch: 123, Loss: 0.070289
Epoch: 124, Loss: 0.069840
Epoch: 125, Loss: 0.072436
Epoch: 126, Loss: 0.071253
Epoch: 127, Loss: 0.070375
Epoch: 128, Loss: 0.066417
Epoch: 129, Loss: 0.075259
Epoch: 130, Loss: 0.064354
Epoch: 131, Loss: 0.070606
Epoch: 132, Loss: 0.071922
Epoch: 133, Loss: 0.071119
Epoch: 134, Loss: 0.069547
Epoch: 135, Loss: 0.072522
Epoch: 136, Loss: 0.074699
Epoch: 137, Loss: 0.071863
Epoch: 138, Loss: 0.072200
Epoch: 139, Loss: 0.074441
Epoch: 140, Loss: 0.067206
Epoch: 141, Loss: 0.072877
Epoch: 142, Loss: 0.068895
Epoch: 143, Loss: 0.071089
Epoch: 144, Loss: 0.066699
Epoch: 145, Loss: 0.071826
Epoch: 146, Loss: 0.070370
Epoch: 147, Loss: 0.072082
Epoch: 148, Loss: 0.071460
Epoch: 149, Loss: 0.068989
Epoch: 150, Loss: 0.066633
Epoch: 151, Loss: 0.072288
Epoch: 152, Loss: 0.071308
Epoch: 153, Loss: 0.065178
Epoch: 154, Loss: 0.068924
Epoch: 155, Loss: 0.071256
Epoch: 156, Loss: 0.066952
Epoch: 157, Loss: 0.071710
Epoch: 158, Loss: 0.068188
Epoch: 159, Loss: 0.067047
Epoch: 160, Loss: 0.067742
Epoch: 161, Loss: 0.069263
Epoch: 162, Loss: 0.067858
Epoch: 163, Loss: 0.071072
Epoch: 164, Loss: 0.067704
Epoch: 165, Loss: 0.071969
Epoch: 166, Loss: 0.071830
Epoch: 167, Loss: 0.068850
Epoch: 168, Loss: 0.067509
Epoch: 169, Loss: 0.065914
Epoch: 170, Loss: 0.071041
Epoch: 171, Loss: 0.066750
Epoch: 172, Loss: 0.066074
Epoch: 173, Loss: 0.067145
Epoch: 174, Loss: 0.071625
Epoch: 175, Loss: 0.064347
Epoch: 176, Loss: 0.064362
Epoch: 177, Loss: 0.070066
Epoch: 178, Loss: 0.066533
Epoch: 179, Loss: 0.064866
Epoch: 180, Loss: 0.064255
Epoch: 181, Loss: 0.067121
Epoch: 182, Loss: 0.068634
Epoch: 183, Loss: 0.069918
Epoch: 184, Loss: 0.069585
Epoch: 185, Loss: 0.067911
Epoch: 186, Loss: 0.073904
Epoch: 187, Loss: 0.067280
Epoch: 188, Loss: 0.072956
Epoch: 189, Loss: 0.071741
Epoch: 190, Loss: 0.068633
Epoch: 191, Loss: 0.069150
Epoch: 192, Loss: 0.068628
Epoch: 193, Loss: 0.067248
Epoch: 194, Loss: 0.069399
Epoch: 195, Loss: 0.070808
Epoch: 196, Loss: 0.067911
Epoch: 197, Loss: 0.067657
Epoch: 198, Loss: 0.068822
Epoch: 199, Loss: 0.068273
